import os
import time
import psutil
import summarizer
import streamlit as st
from util import json_to_csv
from typing import Tuple, Optional
from sentiment import decide_sentiment
from preprocessing import preprocess_json
from crawlers import naver_crawl, news_crawl
from finance.finance_reader import decide_stock_market
from visualizer.finance_visual import run_finance_visual
from models.predict_model_script import run_predict_model
from visualizer.sentiment_visual import run_sentiment_visual
from PIL import Image

# ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
DATA_DIR = "data"
PROCESSED_DIR = os.path.join(DATA_DIR, "processed_articles")
NAVER_DIR = os.path.join(DATA_DIR, "naver_articles")
NEWS_DIR = os.path.join(DATA_DIR, "news_articles")

VALID_SOURCES = {
    'êµ­ë‚´': ('naver_crawl', NAVER_DIR, 'naver'),
    'í•´ì™¸': ('news_crawl', NEWS_DIR, 'news')
}

# ì„±ëŠ¥ ì¸¡ì • í•¨ìˆ˜
def start_performance() -> Tuple[psutil.Process, psutil._common.pcputimes, float]:
    process = psutil.Process(os.getpid())
    start_cpu_times = process.cpu_times()
    start_wall = time.time()
    st.sidebar.write("[INFO]: ì„±ëŠ¥ ì¸¡ì • ì‹œì‘")
    return process, start_cpu_times, start_wall


def measure_performance(start_cpu_times: psutil._common.pcputimes, start_wall: float,
                        end_cpu_times: psutil._common.pcputimes, end_wall: float) -> None:
    user_time = end_cpu_times.user - start_cpu_times.user
    system_time = end_cpu_times.system - start_cpu_times.system
    total_cpu_time = user_time + system_time
    wall_time = end_wall - start_wall

    st.sidebar.write("\n======================================================================")
    st.sidebar.write(
        f"[INFO]: CPU times: user {user_time:.2f} s, sys {system_time:.2f} s, total: {total_cpu_time:.2f} s")
    st.sidebar.write(f"[INFO]: Wall time: {wall_time:.2f} s")
    st.sidebar.write("======================================================================\n")


def ensure_directory(path: str) -> None:
    if not os.path.exists(path):
        os.makedirs(path)
        st.sidebar.write(f"[INFO] ë””ë ‰í† ë¦¬ ìƒì„±: {path}")


def crawl_articles(source: str, company_name: str) -> Optional[Tuple[str, str, str]]:
    try:
        crawl_function, input_dir, crawl_domain = VALID_SOURCES[source]
        st.success(f"{source} ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤...")
        if crawl_function == 'naver_crawl':
            naver_crawl.run(company_name)
        elif crawl_function == 'news_crawl':
            news_crawl.run(company_name)
        else:
            st.error("[ERROR] ì•Œ ìˆ˜ ì—†ëŠ” í¬ë¡¤ëŸ¬ì…ë‹ˆë‹¤.")
            return None
        st.success("ë‰´ìŠ¤ í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return input_dir, crawl_domain, company_name
    except Exception as e:
        st.error(f"[ERROR] í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def summarize_articles(input_dir: str, output_dir: str, company_name: str, source: str) -> None:
    st.write("\n===== [ê¸°ì‚¬ ìš”ì•½] =====")
    summarizer.run(input_dir, output_dir, company_name, source)


def display_crawled_articles(input_dir: str, num: int = 5) -> None:
    try:
        import json
        articles = []
        for filename in os.listdir(input_dir):
            if filename.endswith('.json'):
                with open(os.path.join(input_dir, filename), 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    articles.extend(data.get('articles', []))

        if articles:
            st.subheader(f"í¬ë¡¤ë§ëœ ê¸°ì‚¬ ëª©ë¡ (ìƒìœ„ {num}ê°œ)")
            for article in articles[:num]:
                with st.expander(article.get('title')):
                    st.write(article.get('content'))
        else:
            st.write("í¬ë¡¤ë§ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.write(f"[ERROR] ê¸°ì‚¬ë¥¼ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def main():
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(page_title="ì£¼ì‹ ë‰´ìŠ¤ ë¶„ì„ ì• í”Œë¦¬ì¼€ì´ì…˜", layout="wide", initial_sidebar_state="expanded")

    # ë¡œê³  ì¶”ê°€ (ì˜µì…˜)
    if os.path.exists("logo.png"):
        logo = Image.open("logo.png")
        st.image(logo, width=150)

    st.title("STOCKGEINE")

    st.markdown("""
    ###ğŸ’¡ ìƒì„±í˜•AIë¥¼ í™œìš©í•œ ì£¼ì‹ ì˜ˆì¸¡ í”„ë¡œê·¸ë¨ ê°œë°œ
    ì„ íƒí•œ ì‹œì¥ì—ì„œ ê¸°ì—… ê´€ë ¨ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•˜ê³ , ìš”ì•½í•˜ë©°, ê°ì„± ë¶„ì„ê³¼ ì£¼ê°€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    **ì£¼ìš” ê¸°ëŠ¥:**
    - ğŸ“° ë‰´ìŠ¤ í¬ë¡¤ë§
    - âœ‚ï¸ ê¸°ì‚¬ ìš”ì•½
    - ğŸ“Š ê°ì„± ë¶„ì„
    - ğŸ”® ì£¼ê°€ ì˜ˆì¸¡
    - ğŸ“‰ ê²°ê³¼ ì‹œê°í™”
    """)

    # ì‚¬ì´ë“œë°”ì— ì…ë ¥ ì •ë³´ ë°°ì¹˜
    st.sidebar.header("ğŸ“¥ ì…ë ¥ ì •ë³´")
    source = st.sidebar.selectbox('ì‹œì¥ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”', ['êµ­ë‚´', 'í•´ì™¸'])
    company_name = st.sidebar.text_input("ê¸°ì—… ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")

    st.sidebar.markdown("---")
    st.sidebar.info("ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì£¼ì‹ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•˜ê³ , ìš”ì•½í•˜ë©°, ê°ì„± ë¶„ì„ ë° ì£¼ê°€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

    # ë””ë ‰í† ë¦¬ ì„¤ì •
    ensure_directory(PROCESSED_DIR)

    if st.sidebar.button("í”„ë¡œì„¸ìŠ¤ ì‹œì‘"):
        if not company_name:
            st.sidebar.error("ê¸°ì—… ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()

        with st.spinner("í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤..."):
            # ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
            process, start_cpu_times, start_wall = start_performance()

            # ì§„í–‰ ìƒí™© í‘œì‹œê¸° ì´ˆê¸°í™”
            progress_bar = st.sidebar.progress(0)
            steps = 7
            step = 0

            # ë‰´ìŠ¤ í¬ë¡¤ë§
            crawl_result = crawl_articles(source, company_name)
            if not crawl_result:
                st.sidebar.error("í¬ë¡¤ë§ì— ì‹¤íŒ¨í•˜ì—¬ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                st.stop()
            step += 1
            progress_bar.progress(step / steps)

            input_dir, crawl_domain, company_name = crawl_result
            st.write(
                f"ğŸ“‚ **ì…ë ¥ ë””ë ‰í† ë¦¬**: {input_dir} \n"
                f"ğŸŒ **í¬ë¡¤ ë„ë©”ì¸**: {crawl_domain} \n"
                f"ğŸ¢ **ê¸°ì—… ì´ë¦„**: {company_name} \n"
                f"ğŸ“ˆ **ì‹œì¥ ìœ í˜•**: {source}"
            )

            # ê¸°ì‚¬ ìš”ì•½
            summarize_articles(input_dir, PROCESSED_DIR, company_name, crawl_domain)
            step += 1
            progress_bar.progress(step / steps)

            # í¬ë¡¤ë§ëœ ê¸°ì‚¬ í‘œì‹œ
            display_crawled_articles(input_dir, num=5)
            step += 1
            progress_bar.progress(step / steps)

            # ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„
            try:
                preprocess_json(source, PROCESSED_DIR, company_name)
                step += 1
                progress_bar.progress(step / steps)

                decide_sentiment(source, PROCESSED_DIR, company_name)
                step += 1
                progress_bar.progress(step / steps)

                json_to_csv.run(company_name, crawl_domain)
                step += 1
                progress_bar.progress(step / steps)

                decide_stock_market(source, company_name)
                step += 1
                progress_bar.progress(step / steps)

                run_predict_model(company_name, source)
                step += 1
                progress_bar.progress(step / steps)

                run_sentiment_visual(company_name)
                run_finance_visual(company_name)
                step += 1
                progress_bar.progress(step / steps)
            except Exception as e:
                st.error(f"[ERROR]: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            finally:
                measure_performance(start_cpu_times, start_wall, process.cpu_times(), time.time())
                progress_bar.empty()
                st.success("í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # íƒ­ì„ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ í‘œì‹œ
    tabs = st.tabs(["ğŸ“„ ìš”ì•½ëœ ê¸°ì‚¬", "ğŸ“Š ê°ì„± ë¶„ì„", "ğŸ“ˆ ì£¼ì‹ ë¶„ì„", "ğŸ”® ì˜ˆì¸¡ ëª¨ë¸", "ğŸ“‰ ì‹œê°í™”"])

    with tabs[0]:
        st.header("ğŸ“„ ìš”ì•½ëœ ê¸°ì‚¬")
        num_articles = st.slider("í‘œì‹œí•  ê¸°ì‚¬ ìˆ˜", min_value=1, max_value=20, value=5)
        display_crawled_articles(PROCESSED_DIR, num=num_articles)

    with tabs[1]:
        st.header("ğŸ“Š ê°ì„± ë¶„ì„ ê²°ê³¼")
        # ê°ì„± ë¶„ì„ ê²°ê³¼ í‘œì‹œ ë¡œì§ ì¶”ê°€
        st.write("ê°ì„± ë¶„ì„ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

    with tabs[2]:
        st.header("ğŸ“ˆ ì£¼ì‹ ë¶„ì„ ê²°ê³¼")
        # ì£¼ì‹ ë¶„ì„ ê²°ê³¼ í‘œì‹œ ë¡œì§ ì¶”ê°€
        st.write("ì£¼ì‹ ë¶„ì„ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

    with tabs[3]:
        st.header("ğŸ”® ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼")
        # ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼ í‘œì‹œ ë¡œì§ ì¶”ê°€
        st.write("ì˜ˆì¸¡ ëª¨ë¸ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

    with tabs[4]:
        st.header("ğŸ“‰ ì‹œê°í™” ê²°ê³¼")
        # ì‹œê°í™” ê²°ê³¼ í‘œì‹œ ë¡œì§ ì¶”ê°€
        st.write("ì‹œê°í™” ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

    # í‘¸í„° ì¶”ê°€
    st.markdown("""
    ---
    Developed by [Your Name](https://yourwebsite.com)
    """)


if __name__ == '__main__':
    main()

